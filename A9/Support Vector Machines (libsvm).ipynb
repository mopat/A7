{
 "metadata": {
  "name": "",
  "signature": "sha256:62e91f21e93a2c6d3aec211a267b6a707a92b9350a46d583a35733ddb5abdeff"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Using Support Vector Machines (SVMs) for Classifying Feature Vectors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Workflow:\n",
      "### Feature Extraction\n",
      "**Goal:** transform data in such a way that the characteristic components are available as numerical or categorical values.\n",
      "\n",
      "**Example:** apply FFT to a waveform to extract frequency components\n",
      "\n",
      "### Standardization\n",
      "[usually consists of two steps](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling):\n",
      "\n",
      "* **mean removal** ('center' all values around mean)\n",
      "* **normalization** (map all values to a certain range)\n",
      "\n",
      "([When to standardize data](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html))\n",
      "\n",
      "### Training the Classifier / Predicting Labels\n",
      "\n",
      "* good for numerical data: Support Vector Machines (SVMs)\n",
      "  * libSVM (used below): C library with (ugly) Python bindings, manages standardization by itself\n",
      "  * [SciKit Learn](http://scikit-learn.org/): Python toolkit supporting many different machine-learning approaches (no Python 3 package in Debian, [create package yourself](http://scikit-learn.org/stable/install.html))\n",
      "* alternatives: neural networks, Naive Bayes classifiers, ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import svmutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sensor_reading_1 = [210, 142] # a feature vector with two *features*\n",
      "sensor_reading_2 = [701, 501] # another one"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "gesture_a = [[312,200], [331,375], [124, 89]]  # three feature vectors indicative of gesture A\n",
      "gesture_b = [[897,750], [1000,600], [731, 608]]  # three feature vectors indicative of gesture B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter(*zip(*gesture_a), c='r')\n",
      "scatter(*zip(*gesture_b), c='g')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter(*zip(*gesture_a), c='r')\n",
      "scatter(*zip(*gesture_b), c='g')\n",
      "scatter(*sensor_reading_1, c='y')\n",
      "scatter(*sensor_reading_2, c='b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_vectors = gesture_a + gesture_b\n",
      "labels = [-1] * len(gesture_a) + [1] * len(gesture_b)\n",
      "print(labels, feature_vectors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm_model = svmutil.svm_train(labels, feature_vectors, '-t 0') # '-t 0': use linear kernel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first argument here: expected classes - only needed if you want to automatically measure the accuracy of your classifier\n",
      "pred_labels, pred_accuracy, pred_value = svmutil.svm_predict([-1, 1], [sensor_reading_1, sensor_reading_2], svm_model) \n",
      "print(pred_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Be careful to use the correct parameters!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm_model = svmutil.svm_train(labels, feature_vectors, '-t 2') # '-t 2': use radial kernel (default!)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# same as above\n",
      "pred_labels, pred_accuracy, pred_value = svmutil.svm_predict([-1, 1], [sensor_reading_1, sensor_reading_2], svm_model) \n",
      "print(pred_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Some tips for using SVMs**\n",
      "* Stay with default values at first but also try other kernels\n",
      "* reduce the dimensionality of your data (i.e., the number of features in your feature vector), e.g. by primary component analysis (PCA)\n",
      "* be careful with time series data, such as pointer movement. For example, transform it into sequences of speed-independent features if movement speed is irrelevant to your application (see *time series segmentation*), transform it into the frequency domain, or normalize the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}